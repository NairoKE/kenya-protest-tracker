{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Kenya Protest Analysis\n",
        "\n",
        "This notebook provides interactive analysis of protest data collected from Twitter regarding the Finance Bill 2024 in Kenya.\n",
        "\n",
        "## Contents\n",
        "1. Data Loading and Preprocessing\n",
        "2. Sentiment Analysis\n",
        "3. Temporal Analysis\n",
        "4. Geographical Analysis\n",
        "5. Topic Modeling\n",
        "6. Interactive Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import folium\n",
        "from folium import plugins\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 50)\n",
        "\n",
        "# Load the latest data files\n",
        "data_dir = Path('../data')\n",
        "analysis_dir = data_dir / 'analysis'\n",
        "\n",
        "def get_latest_file(directory, pattern):\n",
        "    files = list(directory.glob(pattern))\n",
        "    if files:\n",
        "        return max(files, key=lambda x: x.stat().st_mtime)\n",
        "    return None\n",
        "\n",
        "tweets_file = get_latest_file(data_dir, 'tweets_*.csv')\n",
        "sentiment_file = get_latest_file(analysis_dir, 'sentiment_analysis_*.csv')\n",
        "\n",
        "if tweets_file and sentiment_file:\n",
        "    tweets_df = pd.read_csv(tweets_file)\n",
        "    sentiment_df = pd.read_csv(sentiment_file)\n",
        "    print(f\"Loaded {len(tweets_df)} tweets and sentiment data\")\n",
        "else:\n",
        "    print(\"No data files found. Please run the data collection script first.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Temporal Analysis\n",
        "\n",
        "Let's analyze how protest activity and sentiment have changed over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert created_at to datetime\n",
        "tweets_df['created_at'] = pd.to_datetime(tweets_df['created_at'])\n",
        "\n",
        "# Group by date and count tweets\n",
        "daily_activity = tweets_df.groupby(tweets_df['created_at'].dt.date).size()\n",
        "\n",
        "# Plot daily activity\n",
        "plt.figure(figsize=(15, 6))\n",
        "daily_activity.plot(kind='line', marker='o')\n",
        "plt.title('Daily Protest Tweet Activity')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze sentiment over time\n",
        "sentiment_df['created_at'] = pd.to_datetime(sentiment_df['created_at'])\n",
        "daily_sentiment = sentiment_df.groupby(sentiment_df['created_at'].dt.date)['textblob_polarity'].mean()\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "daily_sentiment.plot(kind='line', marker='o')\n",
        "plt.title('Daily Average Sentiment')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Average Sentiment Polarity')\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Topic Analysis\n",
        "\n",
        "Let's analyze the main topics and concerns being discussed in the protest tweets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create word cloud of tweet content\n",
        "text = ' '.join(tweets_df['text'])\n",
        "wordcloud = WordCloud(\n",
        "    width=1600, \n",
        "    height=800,\n",
        "    background_color='white',\n",
        "    max_words=100\n",
        ").generate(text)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Words in Protest Tweets')\n",
        "plt.show()\n",
        "\n",
        "# Analyze hashtag frequency\n",
        "hashtags = []\n",
        "for tags in tweets_df['hashtags']:\n",
        "    if isinstance(tags, str):\n",
        "        hashtags.extend(eval(tags))\n",
        "\n",
        "hashtag_freq = pd.Series(hashtags).value_counts()\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "hashtag_freq.head(15).plot(kind='bar')\n",
        "plt.title('Most Common Hashtags')\n",
        "plt.xlabel('Hashtag')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Engagement Analysis\n",
        "\n",
        "Let's analyze which tweets and topics generate the most engagement (retweets and favorites).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate total engagement\n",
        "tweets_df['total_engagement'] = tweets_df['retweet_count'] + tweets_df['favorite_count']\n",
        "\n",
        "# Get most engaging tweets\n",
        "most_engaging = tweets_df.nlargest(10, 'total_engagement')[\n",
        "    ['text', 'retweet_count', 'favorite_count', 'total_engagement']\n",
        "]\n",
        "\n",
        "print(\"Most Engaging Tweets:\")\n",
        "print(most_engaging.to_string())\n",
        "\n",
        "# Plot engagement distribution\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.hist(tweets_df['total_engagement'], bins=50)\n",
        "plt.title('Distribution of Tweet Engagement')\n",
        "plt.xlabel('Total Engagement (Retweets + Favorites)')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.yscale('log')  # Use log scale for better visualization\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Analyze engagement by sentiment\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.boxplot(x='huggingface_label', y='total_engagement', data=pd.merge(tweets_df, sentiment_df))\n",
        "plt.title('Tweet Engagement by Sentiment')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Total Engagement')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Interactive Map Visualization\n",
        "\n",
        "Create an interactive map showing protest locations and sentiment distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create base map centered on Kenya\n",
        "m = folium.Map(location=[-1.2921, 36.8219], zoom_start=7)\n",
        "\n",
        "# Add marker cluster\n",
        "marker_cluster = plugins.MarkerCluster().add_to(m)\n",
        "\n",
        "# Merge tweet and sentiment data\n",
        "merged_df = pd.merge(tweets_df, sentiment_df)\n",
        "\n",
        "# Process each tweet with location data\n",
        "for idx, row in merged_df.iterrows():\n",
        "    if row['coordinates']:\n",
        "        # Determine color based on sentiment\n",
        "        color = 'gray'\n",
        "        if row['huggingface_label'] == 'POS':\n",
        "            color = 'green'\n",
        "        elif row['huggingface_label'] == 'NEG':\n",
        "            color = 'red'\n",
        "        \n",
        "        # Create popup content\n",
        "        popup_content = f\"\"\"\n",
        "        <b>Tweet:</b> {row['text']}<br>\n",
        "        <b>Time:</b> {row['created_at']}<br>\n",
        "        <b>Sentiment:</b> {row['huggingface_label']}<br>\n",
        "        <b>Engagement:</b> {row['total_engagement']}\n",
        "        \"\"\"\n",
        "        \n",
        "        # Add marker\n",
        "        folium.Marker(\n",
        "            location=row['coordinates'],\n",
        "            popup=folium.Popup(popup_content, max_width=300),\n",
        "            icon=folium.Icon(color=color)\n",
        "        ).add_to(marker_cluster)\n",
        "\n",
        "# Add heatmap layer\n",
        "heat_data = []\n",
        "for idx, row in merged_df.iterrows():\n",
        "    if row['coordinates']:\n",
        "        # Weight by engagement\n",
        "        weight = row['total_engagement']\n",
        "        heat_data.append([row['coordinates'][0], row['coordinates'][1], weight])\n",
        "\n",
        "plugins.HeatMap(heat_data).add_to(m)\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "# Display map\n",
        "m\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
